{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4afe4a-bf81-4bb9-aa5e-267170877558",
   "metadata": {},
   "source": [
    "### news dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268c1781-99bc-47dc-ab0c-f28acc603b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9932a3-c25a-4aba-9849-bd51696841d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_json(\"data/news.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c835722-3252-42b1-9da8-595ca4b4efe7",
   "metadata": {},
   "source": [
    "#### Checking value counts and values for normalisation. \n",
    "#### Classifying on too many categories is not a wise idea as the model might fail to learn certain categories due to their frequency.\n",
    "#### Best to identify categories and merge so that total frequency for a single \"topic\" can be higher.\n",
    "#### Here topic is basically representation of multiple categories with one merged category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c17189-6b0a-498b-b56b-d68455df8a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POLITICS          35602\n",
       "WELLNESS          17945\n",
       "ENTERTAINMENT     17362\n",
       "TRAVEL             9900\n",
       "STYLE & BEAUTY     9814\n",
       "PARENTING          8791\n",
       "HEALTHY LIVING     6694\n",
       "QUEER VOICES       6347\n",
       "FOOD & DRINK       6340\n",
       "BUSINESS           5992\n",
       "COMEDY             5400\n",
       "SPORTS             5077\n",
       "BLACK VOICES       4583\n",
       "HOME & LIVING      4320\n",
       "PARENTS            3955\n",
       "THE WORLDPOST      3664\n",
       "WEDDINGS           3653\n",
       "WOMEN              3572\n",
       "CRIME              3562\n",
       "IMPACT             3484\n",
       "DIVORCE            3426\n",
       "WORLD NEWS         3299\n",
       "MEDIA              2944\n",
       "WEIRD NEWS         2777\n",
       "GREEN              2622\n",
       "WORLDPOST          2579\n",
       "RELIGION           2577\n",
       "STYLE              2254\n",
       "SCIENCE            2206\n",
       "TECH               2104\n",
       "TASTE              2096\n",
       "MONEY              1756\n",
       "ARTS               1509\n",
       "ENVIRONMENT        1444\n",
       "FIFTY              1401\n",
       "GOOD NEWS          1398\n",
       "U.S. NEWS          1377\n",
       "ARTS & CULTURE     1339\n",
       "COLLEGE            1144\n",
       "LATINO VOICES      1130\n",
       "CULTURE & ARTS     1074\n",
       "EDUCATION          1014\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ecfd68a-2639-4e74-991d-41e3bf350540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the category normalization as discussed earlier\n",
    "\n",
    "# 1. Combine \"GREEN\" and \"ENVIRONMENT\" into \"ENVIRONMENT\"\n",
    "news_df['category'] = news_df['category'].replace(['GREEN', 'ENVIRONMENT'], 'ENVIRONMENT')\n",
    "\n",
    "# 2. Combine \"QUEER VOICES\", \"BLACK VOICES\", and \"LATINO VOICES\" into \"DIVERSE VOICES\"\n",
    "news_df['category'] = news_df['category'].replace(['QUEER VOICES', 'BLACK VOICES', 'LATINO VOICES'], 'DIVERSE VOICES')\n",
    "\n",
    "# 3. Combine \"WORLDPOST\" and \"THE WORLDPOST\" into \"WORLD NEWS\"\n",
    "news_df['category'] = news_df['category'].replace(['WORLDPOST', 'THE WORLDPOST'], 'WORLD NEWS')\n",
    "\n",
    "# 4. Combine \"PARENTING\" and \"PARENTS\" into \"PARENTING\"\n",
    "news_df['category'] = news_df['category'].replace(['PARENTING', 'PARENTS'], 'PARENTING')\n",
    "\n",
    "# 5. Combine \"ARTS\", \"ARTS & CULTURE\", and \"CULTURE & ARTS\" into \"ARTS & CULTURE\"\n",
    "news_df['category'] = news_df['category'].replace(['ARTS', 'ARTS & CULTURE', 'CULTURE & ARTS'], 'ARTS & CULTURE')\n",
    "\n",
    "# 6. Combine \"TECH\" and \"SCIENCE\" into \"TECH & SCIENCE\"\n",
    "news_df['category'] = news_df['category'].replace(['TECH', 'SCIENCE'], 'TECH & SCIENCE')\n",
    "\n",
    "# 7. Combine \"TASTE\" and \"FOOD & DRINK\" into \"FOOD & DRINK\"\n",
    "news_df['category'] = news_df['category'].replace(['TASTE', 'FOOD & DRINK'], 'FOOD & DRINK')\n",
    "\n",
    "# 8. Combine \"MONEY\", \"BUSINESS\" into \"BUSINESS & FINANCE\"\n",
    "news_df['category'] = news_df['category'].replace(['MONEY', 'BUSINESS'], 'BUSINESS & FINANCE')\n",
    "\n",
    "# 9. Combine \"COLLEGE\", \"EDUCATION\" into \"EDUCATION\"\n",
    "news_df['category'] = news_df['category'].replace(['COLLEGE', 'EDUCATION'], 'EDUCATION')\n",
    "\n",
    "# 9. Combine \"STYLE\", \"STYLE AND BEAUTY\" into \"STYLE & BEAUTY\"\n",
    "news_df['category'] = news_df['category'].replace(['STYLE', 'STYLE & BEAUTY', 'STYLE AND BEAUTY'], 'STYLE & BEAUTY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2061e4-32c3-41b3-a234-9cb63068ce0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POLITICS              35602\n",
       "WELLNESS              17945\n",
       "ENTERTAINMENT         17362\n",
       "PARENTING             12746\n",
       "STYLE & BEAUTY        12068\n",
       "DIVERSE VOICES        12060\n",
       "TRAVEL                 9900\n",
       "WORLD NEWS             9542\n",
       "FOOD & DRINK           8436\n",
       "BUSINESS & FINANCE     7748\n",
       "HEALTHY LIVING         6694\n",
       "COMEDY                 5400\n",
       "SPORTS                 5077\n",
       "HOME & LIVING          4320\n",
       "TECH & SCIENCE         4310\n",
       "ENVIRONMENT            4066\n",
       "ARTS & CULTURE         3922\n",
       "WEDDINGS               3653\n",
       "WOMEN                  3572\n",
       "CRIME                  3562\n",
       "IMPACT                 3484\n",
       "DIVORCE                3426\n",
       "MEDIA                  2944\n",
       "WEIRD NEWS             2777\n",
       "RELIGION               2577\n",
       "EDUCATION              2158\n",
       "FIFTY                  1401\n",
       "GOOD NEWS              1398\n",
       "U.S. NEWS              1377\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Showing new categories\n",
    "news_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fac124-3ba8-4c88-8861-89f5ddee6910",
   "metadata": {},
   "source": [
    "#### Analyzing headlines and short description as only one can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3dbb94-2ec3-4822-a0d2-c8656f1b584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null in headlines and short descriptions\n",
    "# Count of missing values\n",
    "missing_headlines = news_df[\"headline\"].isnull().sum()\n",
    "missing_descriptions = news_df[\"short_description\"].isnull().sum()\n",
    "missing_headlines, missing_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2f7fa-81af-4677-9675-d3bd0a2e831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As no NaNs or nulls are found checking for empty string\n",
    "# Count of empty strings\n",
    "empty_headlines = news_df[news_df[\"headline\"] == \"\"].shape[0]\n",
    "empty_descriptions = news_df[news_df[\"short_description\"] == \"\"].shape[0]\n",
    "\n",
    "# Distribution of string lengths for non-empty values\n",
    "headline_lengths_non_empty = news_df[news_df[\"headline\"] != \"\"][\"headline\"].apply(len)\n",
    "description_lengths_non_empty = news_df[news_df[\"short_description\"] != \"\"][\"short_description\"].apply(len)\n",
    "\n",
    "headline_stats_non_empty = headline_lengths_non_empty.describe()\n",
    "description_stats_non_empty = description_lengths_non_empty.describe()\n",
    "\n",
    "empty_headlines, empty_descriptions, headline_stats_non_empty, description_stats_non_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeab34a-c911-4ff5-978a-064db2d47e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing short descriptions by category\n",
    "# Filter rows with empty short_description\n",
    "empty_description_data = news_df[news_df[\"short_description\"] == \"\"]\n",
    "\n",
    "# Count of empty descriptions by category\n",
    "empty_description_by_category = empty_description_data[\"category\"].value_counts()\n",
    "\n",
    "empty_description_by_category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a109265-e70b-41e7-a512-7cbcd31818da",
   "metadata": {},
   "source": [
    "### Final Analysis:\n",
    "#### 1. Considering that we have missing values, and the problem looks even more exacerbated within larger categories, training on headlines would be a better method.\n",
    "#### 2. US and world news category are mixed categories which will have data representing other categories. Therefore can be considered to be removed from the set and they should be trained as a secondary class or a classification between themseleves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46caceeb-66b6-40bf-aff5-47b693c3c0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
